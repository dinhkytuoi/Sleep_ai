import glob
import os
import numpy as np
import scipy.signal
import tensorflow as tf
from datetime import datetime, timedelta
from sklearn.metrics import classification_report, cohen_kappa_score, f1_score, confusion_matrix
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from sklearn.utils.multiclass import unique_labels

# Import t·ª´ file train - ƒê·∫£m b·∫£o ƒë√¢y l√† file training ch√≠nh x√°c
from TrainLSTM6lop import (
    AttentionLayer, focal_loss, hmm_smoothing_viterbi, CONFIG, load_single_subject, SEED, load_trained_model_for_inference
)
from fine_tune_subject_v2 import (
    run_finetuning_for_subject
)


# =========================================================
# ÔøΩüí° H√†m g·ª£i √Ω gi·ªù th·ª©c d·∫≠y
# =========================================================
def get_optimal_wakeup_times(sleep_stage_seq, start_time, choice, age, gender):
    optimal_times = []
    if choice == '1':
        # S·ª¨A L·ªñI: 30 gi√¢y, kh√¥ng ph·∫£i 30 ph√∫t. M·ªói stage l√† 1 epoch 30 gi√¢y.
        for i, stage in enumerate(sleep_stage_seq): # type: ignore
            wakeup_time = start_time + timedelta(seconds=(i + 1) * 30)
            if stage in ['N1', 'N2', 'REM']: # D·ª±a tr√™n t√™n stage, kh√¥ng ph·∫£i s·ªë
                optimal_times.append(wakeup_time.strftime("%H:%M"))
    elif choice == '2':
        total_minutes = len(sleep_stage_seq) * 0.5 # m·ªói sample = 0.5 ph√∫t
        num_cycles = int(total_minutes // 90) # type: ignore
        for i in range(1, num_cycles + 1):
            wakeup_time = start_time + timedelta(minutes=90 * i)
            optimal_times.append(wakeup_time.strftime("%H:%M"))
    else:
        print("‚ö†Ô∏è L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá. S·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh: 90 ph√∫t.")
        return get_optimal_wakeup_times(sleep_stage_seq, start_time, '2', age, gender)

    # L·ªùi khuy√™n c√° nh√¢n h√≥a
    if choice == '1':
        if gender.lower() == 'nam':
            print("üí° Nam gi·ªõi th∆∞·ªùng c√≥ √≠t gi·∫•c ng·ªß REM h∆°n, c·∫ßn ƒë·∫£m b·∫£o ng·ªß s√¢u.")
        elif gender.lower() == 'n·ªØ':
            print("üí° N·ªØ gi·ªõi th∆∞·ªùng c√≥ nhi·ªÅu REM h∆°n, quan tr·ªçng cho tr√≠ nh·ªõ & c·∫£m x√∫c.")
    elif choice == '2' and age.isdigit() and int(age) > 65:
        print("üí° Ng∆∞·ªùi l·ªõn tu·ªïi th∆∞·ªùng ng·ªß ng·∫Øn h∆°n, c√≥ th·ªÉ th·ª≠ d·∫≠y s·ªõm h∆°n.")

    # Lo·∫°i b·ªè c√°c gi·ªù tr√πng l·∫∑p li√™n ti·∫øp
    unique_times = []
    if optimal_times:
        unique_times.append(optimal_times[0])
        for t in optimal_times[1:]:
            if t != unique_times[-1]:
                unique_times.append(t)

    return unique_times


# =========================================================
# üìä Ph√¢n t√≠ch nhi·ªÖu + tr·ª±c quan
# =========================================================
def generate_noise_impact_report(y_true, y_pred, config, subject_id="Unknown"):
    os.makedirs("final_reports", exist_ok=True)

    print("\n===== üìä PH√ÇN T√çCH ·∫¢NH H∆Ø·ªûNG NHI·ªÑU =====")
    is_clean_mask = (y_true != 5) # Nh√£n nhi·ªÖu l√† 5 trong file TrainLSTM6lop.py # type: ignore

    total_samples = len(y_true)
    noise_samples = np.sum(~is_clean_mask)
    print(f"T·ªïng m·∫´u: {total_samples}, Nhi·ªÖu: {noise_samples} ({noise_samples/total_samples*100:.2f}%)")

    # --- Ph√¢n t√≠ch hi·ªáu su·∫•t ---
    # 1. T·∫≠p CLEAN (kh√¥ng c√≥ nhi·ªÖu)
    y_true_clean = y_true[is_clean_mask]
    y_pred_clean = y_pred[is_clean_mask]
    f1_clean = f1_score(y_true_clean, y_pred_clean, average='macro', zero_division=0) # type: ignore
    kappa_clean = cohen_kappa_score(y_true_clean, y_pred_clean)

    # 2. T·∫≠p FULL (c√≥ nhi·ªÖu)
    f1_full = f1_score(y_true, y_pred, average='macro', zero_division=0) # type: ignore
    kappa_full = cohen_kappa_score(y_true, y_pred)

    print("\n--- So s√°nh hi·ªáu su·∫•t ---")
    print(f"‚úÖ Macro F1 (S·∫°ch): {f1_clean:.4f} | Kappa (S·∫°ch): {kappa_clean:.4f}")
    print(f"üî¥ Macro F1 (ƒê·∫ßy ƒë·ªß): {f1_full:.4f} | Kappa (ƒê·∫ßy ƒë·ªß): {kappa_full:.4f}")
    print(f"üìâ M·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng c·ªßa nhi·ªÖu (F1 gi·∫£m): {f1_clean - f1_full:.4f}")

    # --- Ph√¢n t√≠ch d·ª± ƒëo√°n tr√™n c√°c m·∫´u nhi·ªÖu ---
    if noise_samples > 0:
        y_pred_on_noise = y_pred[~is_clean_mask]
        noise_pred_counts = pd.Series(y_pred_on_noise).value_counts().sort_index()
        print("\nüìå Ph√¢n b·ªë d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh tr√™n c√°c m·∫´u th·ª±c s·ª± l√† nhi·ªÖu:")
        for stage, count in noise_pred_counts.items(): # type: ignore
            if stage < len(config.SLEEP_STAGE_LABELS):
                print(f"  - D·ª± ƒëo√°n l√† '{config.SLEEP_STAGE_LABELS[stage]}': {count} m·∫´u ({count / noise_samples * 100:.2f}%)")

    # --- Tr·ª±c quan h√≥a ---
    # Bi·ªÉu ƒë·ªì tr√≤n t·ªâ l·ªá nhi·ªÖu
    plt.figure(figsize=(6, 6))
    plt.pie([total_samples - noise_samples, noise_samples],
            labels=["S·∫°ch", "Nhi·ªÖu"],
            autopct="%1.1f%%", colors=["#66b3ff", "#ff6666"], startangle=90)
    plt.title(f"T·ªâ l·ªá s·∫°ch vs nhi·ªÖu ({subject_id})")
    plt.savefig(f"final_reports/noise_ratio_{subject_id}.png", dpi=300)
    plt.close()

    # Bi·ªÉu ƒë·ªì c·ªôt ph√¢n b·ªë d·ª± ƒëo√°n
    pred_labels = [config.SLEEP_STAGE_LABELS[i] for i in y_pred]
    plt.figure(figsize=(8, 6))
    sns.countplot(x=pred_labels, order=config.SLEEP_STAGE_LABELS, palette="viridis")
    plt.title(f"Ph√¢n b·ªë d·ª± ƒëo√°n ({subject_id})")
    plt.xlabel("Giai ƒëo·∫°n")
    plt.ylabel("S·ªë m·∫´u")
    plt.savefig(f"final_reports/pred_distribution_{subject_id}.png", dpi=300)
    plt.close()


# =========================================================
# üìà V·∫Ω Timeline d·ª± ƒëo√°n gi·∫•c ng·ªß
# =========================================================
def plot_sleep_timeline(y_pred, sleep_start_time, config, subject_id="Unknown"):
    os.makedirs("final_reports", exist_ok=True)

    epochs = np.arange(len(y_pred))
    times = [sleep_start_time + timedelta(seconds=30 * int(i)) for i in epochs]

    plt.figure(figsize=(14, 5))
    # S·ª≠ d·ª•ng plt.step ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì b·∫≠c thang, tr·ª±c quan h∆°n
    plt.step(times, y_pred, where='post', color='royalblue', linewidth=2)
    # S·ª¨A L·ªñI: Cung c·∫•p ƒë·ªß nh√£n cho t·∫•t c·∫£ c√°c v·ªã tr√≠.
    # config.SLEEP_STAGE_LABELS gi·ªù ƒë√¢y c√≥ 6 ph·∫ßn t·ª≠ t·ª´ TrainLSTM6lop.py # type: ignore
    # range(len(config.SLEEP_STAGE_LABELS)) s·∫Ω l√† range(6) -> [0, 1, 2, 3, 4, 5]
    plt.yticks(range(len(config.SLEEP_STAGE_LABELS)), config.SLEEP_STAGE_LABELS)
    plt.gca().invert_yaxis() # ƒê∆∞a Wake l√™n tr√™n c√πng
    plt.xlabel("Th·ªùi gian")
    plt.ylabel("Giai ƒëo·∫°n")
    plt.title(f"Timeline gi·∫•c ng·ªß ({subject_id})")
    plt.grid(True, axis="y", linestyle="--", alpha=0.7)
    plt.tight_layout()
    plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%H:%M'))
    plt.savefig(f"final_reports/sleep_timeline_{subject_id}.png", dpi=300)
    plt.close()

    print(f"‚úÖ Timeline gi·∫•c ng·ªß ƒë√£ l∆∞u: final_reports/sleep_timeline_{subject_id}.png")


# =========================================================
# üîç Grid Search cho c·∫•u h√¨nh inference t·ªët nh·∫•t
# =========================================================
def run_inference_grid_search(model, X_proc, y_true):
    """
    Ch·∫°y grid search tr√™n c√°c tham s·ªë inference ƒë·ªÉ t√¨m F1-score macro t·ªët nh·∫•t.
    T∆∞∆°ng t·ª± logic trong debug_infer.py.
    """
    best = {"f1": -1}
    temps = [0.8, 1.0, 1.2, 1.5, 1.8] # <-- D√£y Temp M·ªöI
    trans_diags = [0.8, 0.5, 0.3, 0.1] # <-- D√£y Diag M·ªöI
    channel_options = [False, True] # False: normal, True: swap
    hmm_options = [True, False] # True: HMM, False: argmax

    print("\n===== üîç B·∫Øt ƒë·∫ßu Grid Search c·∫•u h√¨nh Inference =====")

    for swap in channel_options:
        X_try = X_proc[..., ::-1] if swap else X_proc
        try:
            probs = model.predict(X_try, verbose=0)
        except Exception as e:
            print(f"L·ªói khi d·ª± ƒëo√°n v·ªõi swap={swap}: {e}")
            continue

        for temp in temps:
            p_tmp = np.clip(probs, 1e-12, 1.0)**(1.0/float(temp))
            p_tmp = p_tmp / p_tmp.sum(axis=1, keepdims=True)

            for apply_hmm in hmm_options:
                if not apply_hmm:
                    # Tr∆∞·ªùng h·ª£p kh√¥ng d√πng HMM, ch·ªâ argmax
                    preds = np.argmax(p_tmp, axis=1)
                    td = None # Kh√¥ng c√≥ HMM diag
                    f1 = f1_score(y_true, preds, average='macro', zero_division=0)
                    if f1 > best["f1"]:
                        best.update({"f1": f1, "swap": swap, "temp": temp,
                                     "apply_hmm": apply_hmm, "trans_diag": td, "preds": preds})
                    continue

                # Tr∆∞·ªùng h·ª£p d√πng HMM v·ªõi c√°c diag kh√°c nhau
                for td in trans_diags:
                    # clean_eval=True n·∫øu kh√¥ng c√≥ nh√£n Noise trong y_true
                    clean_eval = not np.any(y_true == 5)
                    preds = hmm_smoothing_viterbi(p_tmp, trans_diag=td, clean_eval=clean_eval)
                    f1 = f1_score(y_true, preds, average='macro', zero_division=0)
                    if f1 > best["f1"]:
                        best.update({"f1": f1, "swap": swap, "temp": temp,
                                     "apply_hmm": apply_hmm, "trans_diag": td, "preds": preds})

    print("\n--- K·∫øt qu·∫£ Grid Search ---")
    if best['f1'] > -1:
        best_config_str = (
            f"F1: {best['f1']:.4f} | Swap: {best['swap']} | Temp: {best['temp']} | "
            f"HMM: {best['apply_hmm']} | Diag: {best['trans_diag']}"
        )
        print(f"‚úÖ C·∫•u h√¨nh t·ªët nh·∫•t: {best_config_str}")
        # Tr·∫£ v·ªÅ d·ª± ƒëo√°n t·ªët nh·∫•t
        return best["preds"]
    else:
        print("‚ö†Ô∏è Grid search kh√¥ng t√¨m th·∫•y c·∫•u h√¨nh h·ª£p l·ªá.")
        # Fallback v·ªÅ argmax c·ªßa probs g·ªëc
        return np.argmax(model.predict(X_proc, verbose=0), axis=1)


# =========================================================
#  MAIN
# =========================================================
if __name__ == "__main__":
    print("\n\n===== üí° Ph√¢n t√≠ch d·ªØ li·ªáu v√† ƒë·ªÅ xu·∫•t gi·ªù th·ª©c d·∫≠y =====")
    
    subject_to_analyze = input("‚ñ∂Ô∏è Nh·∫≠p t√™n file d·ªØ li·ªáu s√≥ng (v√≠ d·ª•: 'SC4581'): ")
    age = input("‚ñ∂Ô∏è Nh·∫≠p tu·ªïi: ")
    gender = input("‚ñ∂Ô∏è Nh·∫≠p gi·ªõi t√≠nh (Nam/N·ªØ): ")

    while True:
        sleep_start_time_str = input("‚ñ∂Ô∏è Nh·∫≠p gi·ªù ƒëi ng·ªß (HH:MM, v√≠ d·ª•: 22:00): ")
        try:
            sleep_start_time = datetime.strptime(sleep_start_time_str, "%H:%M")
            break
        except ValueError:
            print("‚ùå Sai ƒë·ªãnh d·∫°ng, th·ª≠ l·∫°i.")

    # --- S·ª¨A L·ªñI: Logic ch·ªçn model linh ho·∫°t ---
    # 1. ∆Øu ti√™n t√¨m model ƒë√£ fine-tune ri√™ng cho subject
    subject_specific_model_path = f"fine_tuned_v2_{subject_to_analyze}.keras"
    best_model_path = None

    # 1. ∆Øu ti√™n t√¨m model ƒë√£ fine-tune ri√™ng cho subject
    if os.path.exists(subject_specific_model_path):
        best_model_path = subject_specific_model_path
        print(f"‚úÖ T√¨m th·∫•y model ƒë√£ fine-tune ri√™ng cho subject: {best_model_path}")
    elif os.path.exists(f"fine_tuned_{subject_to_analyze}.keras"): # Fallback cho v1
        best_model_path = f"fine_tuned_{subject_to_analyze}.keras"
        print(f"‚úÖ T√¨m th·∫•y model ƒë√£ fine-tune ri√™ng cho subject (v1): {best_model_path}")
    else:
        # 1a. N·∫øu kh√¥ng c√≥, h·ªèi ng∆∞·ªùi d√πng c√≥ mu·ªën fine-tune kh√¥ng
        print(f"‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y model ri√™ng cho '{subject_to_analyze}'.")
        do_finetune = input("‚ñ∂Ô∏è B·∫°n c√≥ mu·ªën fine-tune m·ªôt model m·ªõi cho subject n√†y ƒë·ªÉ c√≥ k·∫øt qu·∫£ t·ªët nh·∫•t? (y/n): ").lower()
        if do_finetune == 'y':
            base_model_path = open("best_model_path.txt").read().strip()
            print(f"\n===== üöÄ B·∫Øt ƒë·∫ßu Fine-tuning cho {subject_to_analyze} t·ª´ model '{base_model_path}' =====")
            best_model_path = run_finetuning_for_subject(subject_to_analyze, base_model_path)
            print(f"===== ‚úÖ Fine-tuning ho√†n t·∫•t. Model m·ªõi: '{best_model_path}' =====\n")

    # 2. N·∫øu v·∫´n kh√¥ng c√≥ model (ng∆∞·ªùi d√πng t·ª´ ch·ªëi fine-tune), fallback v·ªÅ model chung
    if not best_model_path:
        print(f"‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y model ri√™ng cho '{subject_to_analyze}'. T√¨m model chung...")
        # 2. N·∫øu kh√¥ng c√≥, fallback v·ªÅ model chung trong best_model_path.txt
        best_model_path_file = "best_model_path.txt"
        if os.path.exists(best_model_path_file):
            with open(best_model_path_file, "r", encoding="utf-8-sig") as f:
                best_model_path = f.read().strip()
            if best_model_path and os.path.exists(best_model_path):
                print(f"‚ö†Ô∏è  C·∫¢NH B√ÅO: S·ª≠ d·ª•ng model chung '{best_model_path}' v√¨ kh√¥ng c√≥ model ri√™ng cho '{subject_to_analyze}'. K·∫øt qu·∫£ c√≥ th·ªÉ kh√¥ng t·ªëi ∆∞u.")
            else:
                print(f"‚ùå L·ªói: ƒê∆∞·ªùng d·∫´n model '{best_model_path}' trong file '{best_model_path_file}' kh√¥ng h·ª£p l·ªá.")
                best_model_path = None
        else:
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y file '{best_model_path_file}'.")

    if not best_model_path:
        print("‚ùå Kh√¥ng th·ªÉ x√°c ƒë·ªãnh model ƒë·ªÉ s·ª≠ d·ª•ng. Vui l√≤ng ch·∫°y training ho·∫∑c fine-tuning tr∆∞·ªõc.")
        exit()

    print(f"‚úÖ S·ª≠ d·ª•ng model: {best_model_path}")
    model = load_trained_model_for_inference(best_model_path)

    # Load v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu cho subject
    X_raw, y_subject_true = load_single_subject(subject_to_analyze)
    if X_raw is None:
        print(f"‚ùå Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu cho subject {subject_to_analyze}.")
        exit()

    # Ti·ªÅn x·ª≠ l√Ω gi·ªëng h·ªát trong training
    X_list = []
    for i in range(X_raw.shape[0]):
        x = X_raw[i].astype(np.float32)
        x_r = scipy.signal.resample(x, CONFIG.TARGET_LENGTH_LSTM, axis=0).astype(np.float32)
        mean = x_r.mean(axis=0, keepdims=True)
        std = x_r.std(axis=0, keepdims=True) + 1e-8
        X_list.append((x_r - mean) / std)
    X_subject = np.stack(X_list).astype(np.float32)
    y_subject_true = np.array(y_subject_true)

    # Ch·∫°y grid search ƒë·ªÉ t√¨m d·ª± ƒëo√°n t·ªët nh·∫•t
    y_pred_final = run_inference_grid_search(model, X_subject, y_subject_true)

    if y_pred_final is not None and len(y_pred_final) > 0:
        # --- DEBUG: save per-channel stats + PSD for comparison ---
        try:
            os.makedirs("debug_plots", exist_ok=True)
            # X_subject shape = (n_epochs, time_points, channels)
            X = np.array(X_subject)  # ensure ndarray
            n_epochs, n_t, n_ch = X.shape
            ch_means = X.reshape(-1, n_ch).mean(axis=0)
            ch_stds = X.reshape(-1, n_ch).std(axis=0)
            np.save("debug_plots/subject_per_channel_mean.npy", ch_means)
            np.save("debug_plots/subject_per_channel_std.npy", ch_stds)
            print("DEBUG: per-channel mean/std saved:", ch_means, ch_stds)

            # PSD for epoch 0 each channel
            from scipy.signal import welch
            sf = 100  # typical sfreq ‚Äî thay n·∫øu kh√°c (m·ªôt s·ªë file in ra sfreq=100)
            fig, axs = plt.subplots(n_ch, 1, figsize=(8, 2.5 * n_ch))
            for c in range(n_ch):
                f, Pxx = welch(X[0, :, c], fs=sf, nperseg=512)
                axs[c].semilogy(f, Pxx)
                axs[c].set_xlabel("Hz"); axs[c].set_ylabel("PSD")
                axs[c].set_title(f"Subject {subject_to_analyze} PSD epoch0 ch{c}")
            plt.tight_layout()
            plt.savefig(f"debug_plots/{subject_to_analyze}_epoch0_psd.png", dpi=150)
            plt.close()
            print(f"DEBUG: saved PSD -> debug_plots/{subject_to_analyze}_epoch0_psd.png")

            # If you have a saved training example to compare (optional)
            train_sample_path = "debug_plots/training_epoch_sample.npy"
            if os.path.exists(train_sample_path):
                train_epoch = np.load(train_sample_path)  # expects shape (time, channels)
                fig, axs = plt.subplots(n_ch, 1, figsize=(8, 2.5 * n_ch))
                for c in range(n_ch):
                    f_s, P_s = welch(train_epoch[:, c], fs=sf, nperseg=512)
                    f_x, P_x = welch(X[0, :, c], fs=sf, nperseg=512)
                    axs[c].semilogy(f_s, P_s, label="train", alpha=0.8)
                    axs[c].semilogy(f_x, P_x, label="subject", alpha=0.8)
                    axs[c].legend()
                    axs[c].set_title(f"PSD ch{c} train vs subject")
                plt.tight_layout()
                plt.savefig(f"debug_plots/{subject_to_analyze}_psd_vs_train.png", dpi=150)
                plt.close()
                print("DEBUG: saved PSD comparison with training sample")

        except Exception as _e:
            print("DEBUG: failed saving channel stats/PSD:", _e)

        # Ph√¢n t√≠ch nhi·ªÖu
        generate_noise_impact_report(y_subject_true, y_pred_final, CONFIG, subject_id=subject_to_analyze)

        # V·∫Ω timeline
        plot_sleep_timeline(y_pred_final, sleep_start_time, CONFIG, subject_id=subject_to_analyze)

        # --- FIX: t·∫°o danh s√°ch t√™n stage t·ª´ nh√£n s·ªë ƒë·ªÉ d√πng cho g·ª£i √Ω gi·ªù th·ª©c d·∫≠y ---
        try:
            y_pred_stages = [CONFIG.SLEEP_STAGE_LABELS[int(x)] for x in np.array(y_pred_final).astype(int)]
        except Exception:
            y_pred_stages = []

        # ƒê·ªÅ xu·∫•t gi·ªù th·ª©c d·∫≠y d·ª±a tr√™n k·∫øt qu·∫£ ƒë√£ l√†m m∆∞·ª£t
        print("\n--- Ch·ªçn ch·∫ø ƒë·ªô ƒë·ªÅ xu·∫•t ---")
        print("1. D·∫≠y trong giai ƒëo·∫°n nh·∫π (N1, N2, REM)")
        print("2. D·∫≠y sau m·ªói chu k·ª≥ 90 ph√∫t")
        choice = input("‚ñ∂Ô∏è Nh·∫≠p l·ª±a ch·ªçn (1 ho·∫∑c 2): ")

        optimal_times = get_optimal_wakeup_times(y_pred_stages, sleep_start_time, choice, age, gender)

        print(f"\nüìå Ng·ªß l√∫c: {sleep_start_time_str}")
        print(f"üë§ Tu·ªïi: {age}, Gi·ªõi t√≠nh: {gender}")
        if optimal_times:
            print("\n‚è∞ Gi·ªù th·ª©c d·∫≠y t·ªëi ∆∞u:")
            for i, t in enumerate(optimal_times, 1):
                print(f"   {i}. {t}")
        else:
            print("‚ö†Ô∏è Kh√¥ng c√≥ gi·ªù th·ª©c d·∫≠y t·ªëi ∆∞u.")
    else:
        print(f"‚ùå Kh√¥ng th·ªÉ x·ª≠ l√Ω cho subject {subject_to_analyze}.")
