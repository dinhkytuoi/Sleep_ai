import glob
import os
import numpy as np
import scipy.signal
import tensorflow as tf
from pathlib import Path
from datetime import datetime, date, time as dt_time, timedelta
import scipy.signal
import mne
from sklearn.metrics import classification_report, cohen_kappa_score, f1_score, confusion_matrix
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from sklearn.utils.multiclass import unique_labels


# Import t·ª´ file train - ƒê·∫£m b·∫£o ƒë√¢y l√† file training ch√≠nh x√°c
from TrainCNN6lop import (
    hmm_smoothing_viterbi, CONFIG, load_single_subject, SEED, load_trained_model_for_inference
)
from fine_tune_subject_v2_CNN import (
    run_finetuning_for_subject as run_finetuning_for_subject_cnn
)

# =========================================================
# üí° C·∫§U TR√öC D·ªÆ LI·ªÜU Y·∫æU T·ªê ·∫¢NH H∆Ø·ªûNG B√äN NGO√ÄI C√ì PH√ÇN LO·∫†I IMPACT
# (Tr√≠ch t·ª´ Sleep-docs.docx - D√πng ƒë·ªÉ li√™n k·∫øt v·ªõi k·∫øt qu·∫£ ph√¢n t√≠ch)
# =========================================================
SLEEP_IMPACT_FACTORS_DETAIL = {
    "thanh_thieu_nien_tre": {
        "min_age": 15, "max_age": 30,
        "factors": [
            {"desc": "√Åp l·ª±c t√¢m l√Ω: Stress h·ªçc t·∫≠p, c√¥ng vi·ªác, lo √¢u, r·ªëi lo·∫°n c·∫£m x√∫c.", "impacts": ["Wake", "REM", "N3"]},
            {"desc": "Th√≥i quen sinh ho·∫°t: S·ª≠ d·ª•ng thi·∫øt b·ªã ƒëi·ªán t·ª≠, √°nh s√°ng xanh.", "impacts": ["Wake", "N1", "N2"]},
            {"desc": "Gi·ªù gi·∫•c ng·ªß kh√¥ng ƒë·ªÅu, th·ª©c khuya.", "impacts": ["N3", "REM", "Wake"]},
            {"desc": "Ti√™u th·ª• ch·∫•t k√≠ch th√≠ch (caffeine, r∆∞·ª£u, thu·ªëc l√°).", "impacts": ["Wake", "REM"]},
        ]
    },
    "trung_nien": {
        "min_age": 31, "max_age": 65,
        "factors": [
            {"desc": "√Åp l·ª±c cu·ªôc s·ªëng: CƒÉng th·∫≥ng c√¥ng vi·ªác, t√†i ch√≠nh, gia ƒë√¨nh.", "impacts": ["Wake", "N3"]},
            {"desc": "C√°c b·ªánh l√Ω n·ªÅn: Ng∆∞ng th·ªü khi ng·ªß, ƒêau m·∫°n t√≠nh, B√©o ph√¨.", "impacts": ["N3", "Wake"]},
            {"desc": "Thay ƒë·ªïi hormone (n·ªØ gi·ªõi: ti·ªÅn m√£n kinh, m√£n kinh g√¢y b·ªëc h·ªèa).", "impacts": ["Wake"]},
            {"desc": "C√°c b·ªánh l√Ω kh√°c: Cao huy·∫øt √°p, ti·ªÉu ƒë∆∞·ªùng.", "impacts": ["N3", "Wake"]},
        ]
    },
    "cao_tuoi": {
        "min_age": 66, "max_age": 120,
        "factors": [
            {"desc": "Thay ƒë·ªïi sinh l√Ω t·ª± nhi√™n: Gi·∫£m ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß s√¢u, gi·∫£m melatonin.", "impacts": ["N3", "N2"]},
            {"desc": "R·ªëi lo·∫°n nh·ªãp sinh h·ªçc (th·ª©c d·∫≠y s·ªõm).", "impacts": ["TotalSleepTime"]},
            {"desc": "C√°c b·ªánh l√Ω v√† thu·ªëc: Ti·ªÉu ƒë√™m, Ng∆∞ng th·ªü khi ng·ªß, H·ªôi ch·ª©ng ch√¢n kh√¥ng y√™n.", "impacts": ["Wake"]},
            {"desc": "ƒêau x∆∞∆°ng kh·ªõp, b·ªánh tim m·∫°ch, Alzheimer.", "impacts": ["N3", "Wake"]},
            {"desc": "C√°c y·∫øu t·ªë t√¢m l√Ω - x√£ h·ªôi: C√¥ ƒë∆°n, tr·∫ßm c·∫£m, s·ª± thay ƒë·ªïi l·ªõn (ngh·ªâ h∆∞u).", "impacts": ["Wake", "REM"]},
        ]
    }
}

# =========================================================
# üéØ M·ª§C TI√äU: D·ªØ li·ªáu m√¥ t·∫£ ·∫£nh h∆∞·ªüng c·ªßa c√°c giai ƒëo·∫°n gi·∫•c ng·ªß
# =========================================================
SLEEP_STAGE_IMPACT_SUMMARY = {
    "Wake": {
        "desc": "Giai ƒëo·∫°n t·ªânh t√°o gi·ªØa c√°c chu k·ª≥ ng·ªß.",
        "function": "Gi√∫p n√£o chuy·ªÉn giai ƒëo·∫°n, th∆∞·ªùng ng·∫Øn (d∆∞·ªõi 8%).",
        "if_high": "T·ªâ l·ªá Wake cao l√†m gi·∫£m ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß, g√¢y m·ªát m·ªèi, u·ªÉ o·∫£i.",
        "if_low": "", # Wake th·∫•p l√† t·ªët, kh√¥ng c·∫ßn hi·ªÉn th·ªã
        "improve": "Tr√°nh caffeine/r∆∞·ª£u, gi·∫£m stress, gi·ªØ ph√≤ng ng·ªß t·ªëi v√† y√™n tƒ©nh."
    },
    "N1": {
        "desc": "Giai ƒëo·∫°n ng·ªß n√¥ng, d·ªÖ b·ªã ƒë√°nh th·ª©c.",
        "function": "Chuy·ªÉn ti·∫øp t·ª´ t·ªânh sang ng·ªß s√¢u h∆°n.",
        "if_high": "N·∫øu qu√° nhi·ªÅu N1 ‚Üí gi·∫•c ng·ªß b·ªã ph√¢n m·∫£nh, kh√¥ng ph·ª•c h·ªìi.",
        "if_low": "", # N1 th·∫•p l√† t·ªët
        "improve": "Gi·ªØ m√¥i tr∆∞·ªùng y√™n tƒ©nh, nhi·ªát ƒë·ªô m√°t, tr√°nh th·ª©c khuya."
    },
    "N2": {
        "desc": "Giai ƒëo·∫°n ng·ªß v·ª´a ‚Äì chi·∫øm ph·∫ßn l·ªõn th·ªùi gian ng·ªß.",
        "function": "C·ªßng c·ªë tr√≠ nh·ªõ v√† h·ªìi ph·ª•c c∆° b·∫Øp nh·∫π.",
        "if_high": "N·∫øu qu√° nhi·ªÅu m√† N3/REM th·∫•p ‚Üí ng·ªß ch∆∞a ƒë·ªß s√¢u ho·∫∑c do stress.",
        "if_low": "T·ªâ l·ªá N2 th·∫•p b·∫•t th∆∞·ªùng c√≥ th·ªÉ do gi·∫•c ng·ªß b·ªã gi√°n ƒëo·∫°n nhi·ªÅu.",
        "improve": "TƒÉng v·∫≠n ƒë·ªông ban ng√†y, ki·ªÉm so√°t lo √¢u, duy tr√¨ l·ªãch ng·ªß ƒë·ªÅu ƒë·∫∑n."
    },
    "N3": {
        "desc": "Gi·∫•c ng·ªß s√¢u, quan tr·ªçng cho ph·ª•c h·ªìi th·ªÉ ch·∫•t.",
        "function": "TƒÉng ti·∫øt hormone tƒÉng tr∆∞·ªüng, t√°i t·∫°o m√¥, tƒÉng mi·ªÖn d·ªãch.",
        "if_low": "Thi·∫øu N3 ‚Üí d·ªÖ m·ªát, ƒëau nh·ª©c, kh√≥ t·∫≠p trung, suy gi·∫£m mi·ªÖn d·ªãch.",
        "if_high": "", # N3 cao l√† t·ªët
        "improve": "T·∫≠p th·ªÉ d·ª•c ƒë·ªÅu ƒë·∫∑n, gi·ªØ ph√≤ng t·ªëi, tr√°nh caffeine & r∆∞·ª£u bia."
    },
    "REM": {
        "desc": "Giai ƒëo·∫°n m∆°, ph·ª•c h·ªìi n√£o b·ªô v√† c·∫£m x√∫c.",
        "function": "C·ªßng c·ªë tr√≠ nh·ªõ, c√¢n b·∫±ng c·∫£m x√∫c, tƒÉng c∆∞·ªùng s√°ng t·∫°o.",
        "if_low": "Thi·∫øu REM ‚Üí kh√≥ t·∫≠p trung, hay qu√™n, d·ªÖ c√°u g·∫Øt, gi·∫£m kh·∫£ nƒÉng s√°ng t·∫°o.",
        "if_high": "", # REM cao l√† t·ªët
        "improve": "Gi·∫£m stress, thi·ªÅn ƒë·ªãnh, ng·ªß ƒë·ªß 7‚Äì9h, tr√°nh th·ª©c khuya."
    }
}

# =========================================================
# ÔøΩüí° H√†m g·ª£i √Ω gi·ªù th·ª©c d·∫≠y
# =========================================================
def get_optimal_wakeup_times(sleep_stage_seq, start_time, choice, age, gender):
    optimal_times = []
    if choice == '1':
        # S·ª¨A L·ªñI: 30 gi√¢y, kh√¥ng ph·∫£i 30 ph√∫t. M·ªói stage l√† 1 epoch 30 gi√¢y.
        for i, stage in enumerate(sleep_stage_seq): # type: ignore
            wakeup_time = start_time + timedelta(seconds=(i + 1) * 30)
            if stage in ['N1', 'N2', 'REM']: # D·ª±a tr√™n t√™n stage, kh√¥ng ph·∫£i s·ªë
                optimal_times.append(wakeup_time.strftime("%H:%M"))
    elif choice == '2':
        total_minutes = len(sleep_stage_seq) * 0.5 # m·ªói sample = 0.5 ph√∫t
        num_cycles = int(total_minutes // 90) # type: ignore
        for i in range(1, num_cycles + 1):
            wakeup_time = start_time + timedelta(minutes=90 * i)
            optimal_times.append(wakeup_time.strftime("%H:%M"))
    else:
        print("‚ö†Ô∏è L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá. S·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh: 90 ph√∫t.")
        return get_optimal_wakeup_times(sleep_stage_seq, start_time, '2', age, gender)

    # L·ªùi khuy√™n c√° nh√¢n h√≥a
    if choice == '1':
        if gender.lower() == 'nam':
            print("üí° Nam gi·ªõi th∆∞·ªùng c√≥ √≠t gi·∫•c ng·ªß REM h∆°n, c·∫ßn ƒë·∫£m b·∫£o ng·ªß s√¢u.")
        elif gender.lower() == 'n·ªØ':
            print("üí° N·ªØ gi·ªõi th∆∞·ªùng c√≥ nhi·ªÅu REM h∆°n, quan tr·ªçng cho tr√≠ nh·ªõ & c·∫£m x√∫c.")
    elif choice == '2' and age.isdigit() and int(age) > 65:
        print("üí° Ng∆∞·ªùi l·ªõn tu·ªïi th∆∞·ªùng ng·ªß ng·∫Øn h∆°n, c√≥ th·ªÉ th·ª≠ d·∫≠y s·ªõm h∆°n.")

    # Lo·∫°i b·ªè c√°c gi·ªù tr√πng l·∫∑p li√™n ti·∫øp
    unique_times = []
    if optimal_times:
        unique_times.append(optimal_times[0])
        for t in optimal_times[1:]:
            if t != unique_times[-1]:
                unique_times.append(t)

    return unique_times

# =========================================================
# üí° H√†m t√≠nh ƒëi·ªÉm ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß
# =========================================================
def calculate_sleep_quality_score(stage_counts, age):
    """
    T√≠nh to√°n ƒëi·ªÉm ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß d·ª±a tr√™n t·ªâ l·ªá c√°c giai ƒëo·∫°n.
    """
    total_epochs = sum(stage_counts.values())
    if total_epochs == 0:
        return 0, "Kh√¥ng ƒë·ªß d·ªØ li·ªáu"

    age_int = int(age) if age.isdigit() else 40

    # Ng∆∞·ª°ng l√Ω t∆∞·ªüng cho t·ª´ng giai ƒëo·∫°n
    THRESHOLDS = {
        'N3': {'range': (0.13, 0.23) if age_int > 60 else (0.15, 0.25), 'weight': 40},
        'REM': {'range': (0.18, 0.23) if age_int > 60 else (0.20, 0.25), 'weight': 35},
        'Wake': {'range': (0.02, 0.08), 'weight': 25}
    }

    total_score = 0

    # T√≠nh ƒëi·ªÉm cho N3 v√† REM (c√†ng g·∫ßn ng∆∞·ª°ng tr√™n c√†ng t·ªët)
    for stage in ['N3', 'REM']:
        percentage = stage_counts.get(stage, 0) / total_epochs
        min_p, max_p = THRESHOLDS[stage]['range']
        weight = THRESHOLDS[stage]['weight']
        
        if percentage >= min_p:
            # ƒê·∫°t ng∆∞·ª°ng t·ªëi thi·ªÉu, ƒëi·ªÉm tƒÉng d·∫ßn ƒë·∫øn max_p
            stage_score = min(1.0, (percentage - min_p) / (max_p - min_p))
        else:
            # D∆∞·ªõi ng∆∞·ª°ng, ƒëi·ªÉm th·∫•p
            stage_score = max(0, percentage / min_p)
        total_score += stage_score * weight

    # T√≠nh ƒëi·ªÉm cho Wake (c√†ng th·∫•p c√†ng t·ªët)
    wake_percentage = stage_counts.get('Wake', 0) / total_epochs
    min_p_wake, max_p_wake = THRESHOLDS['Wake']['range']
    if wake_percentage <= max_p_wake:
        # N·∫øu trong ng∆∞·ª°ng ho·∫∑c th·∫•p h∆°n, ƒëi·ªÉm t·ªëi ƒëa
        wake_score = 1.0
    else:
        # N·∫øu cao h∆°n ng∆∞·ª°ng, ƒëi·ªÉm gi·∫£m d·∫ßn
        wake_score = max(0, 1.0 - (wake_percentage - max_p_wake) / (0.20 - max_p_wake)) # Gi·∫£m d·∫ßn ƒë·∫øn 20%
    total_score += wake_score * THRESHOLDS['Wake']['weight']

    final_score = int(np.clip(total_score, 0, 100))
    rating = "T·ªët" if final_score >= 75 else "Trung b√¨nh" if final_score >= 50 else "C·∫ßn c·∫£i thi·ªán"
    return final_score, rating

# =========================================================
# üéØ M·ª§C TI√äU: H√†m t·∫°o b·∫£ng ·∫£nh h∆∞·ªüng c√° nh√¢n h√≥a
# =========================================================
def generate_stage_impact_report(stage_counts, age, stage_summary):
    """
    T·∫°o b·∫£ng ph√¢n t√≠ch ƒë·ªông, c√° nh√¢n h√≥a v·ªÅ ·∫£nh h∆∞·ªüng c·ªßa t·ª´ng giai ƒëo·∫°n gi·∫•c ng·ªß.
    """
    total_epochs = sum(stage_counts.values())
    if total_epochs == 0:
        return ["\n‚ö†Ô∏è Kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t·∫°o b·∫£ng ·∫£nh h∆∞·ªüng."]

    lines = ["\n**üìã B·∫¢NG PH√ÇN T√çCH ·∫¢NH H∆Ø·ªûNG C√ÅC GIAI ƒêO·∫†N GI·∫§C NG·ª¶ (C√Å NH√ÇN H√ìA)**",
             "| Giai ƒëo·∫°n | Vai tr√≤ | Tr·∫°ng th√°i | ·∫¢nh h∆∞·ªüng ti·ªÅm t√†ng | G·ª£i √Ω c·∫£i thi·ªán |",
             "| :--- | :--- | :--- | :--- | :--- |"]

    age_int = int(age) if age.isdigit() else 40
    thresholds = {
        'Wake': (0.02, 0.08),
        'N1': (0.02, 0.08),
        'N2': (0.45, 0.55),
        'N3': (0.13, 0.23) if age_int > 60 else (0.15, 0.25),
        'REM': (0.18, 0.23) if age_int > 60 else (0.20, 0.25),
    }

    for stage, (low, high) in thresholds.items():
        pct = stage_counts.get(stage, 0) / total_epochs
        status = "‚úÖ T·ªët"
        effect = "C√°c ch·ªâ s·ªë trong ng∆∞·ª°ng kh·ªèe m·∫°nh."

        if pct < low:
            status = f"‚¨áÔ∏è Th·∫•p ({pct:.1%})"
            effect = stage_summary[stage].get("if_low", "Kh√¥ng c√≥ ·∫£nh h∆∞·ªüng ti√™u c·ª±c ƒë√°ng k·ªÉ.")
        elif pct > high:
            status = f"‚¨ÜÔ∏è Cao ({pct:.1%})"
            effect = stage_summary[stage].get("if_high", "C√≥ th·ªÉ l√† d·∫•u hi·ªáu c·ªßa gi·∫•c ng·ªß k√©m s√¢u.")

        lines.append(
            f"| **{stage}** | {stage_summary[stage]['function']} | {status} | {effect} | {stage_summary[stage]['improve']} |"
        )

    return lines



# =========================================================
# üí° H√†m g·ª£i √Ω l·ªùi khuy√™n c√° nh√¢n h√≥a
# =========================================================
def get_personalized_advice(age, gender, stage_counts, sleep_impact_factors_detail, user_factors=None):
    advice = []
    
    # --- 1. Ph√¢n t√≠ch k·∫øt qu·∫£ gi·∫•c ng·ªß (Stage Percentage) ---
    total_epochs = sum(stage_counts.values())
    if total_epochs == 0:
        return ["‚ö†Ô∏è Kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch v√† ƒë∆∞a ra l·ªùi khuy√™n."]
        
    # ƒê·ªãnh nghƒ©a ng∆∞·ª°ng v√† m√¥ t·∫£
    THRESHOLDS = {
        'N3': {'min_percent': 0.15, 'desc': "Gi·∫•c ng·ªß s√¢u (N3)", 'emoji': 'üí§'}, # C·∫ßn > 15%
        'REM': {'min_percent': 0.20, 'desc': "Gi·∫•c ng·ªß REM", 'emoji': 'üß†'}, # C·∫ßn > 20%
        'Wake': {'max_percent': 0.10, 'desc': "T·ªâ l·ªá th·ª©c gi·∫•c (Wake)", 'emoji': '‚ö°Ô∏è'} # C·∫ßn < 10%
    }
    
    poor_stages = []
    
    # Ki·ªÉm tra t·ª´ng giai ƒëo·∫°n quan tr·ªçng
    for stage, config in THRESHOLDS.items():
        count = stage_counts.get(stage, 0)
        percentage = count / total_epochs
        
        # N·∫øu l√† N3/REM (c·∫ßn cao)
        if 'min_percent' in config and percentage < config['min_percent']:
            poor_stages.append({'stage': stage, 'percent': percentage, 'config': config})
        # N·∫øu l√† Wake (c·∫ßn th·∫•p)
        elif 'max_percent' in config and percentage > config['max_percent']:
            poor_stages.append({'stage': stage, 'percent': percentage, 'config': config})

    # --- 2. (M·ªöI) Ph√¢n t√≠ch c√°c y·∫øu t·ªë ngo·∫°i c·∫£nh t·ª´ ng∆∞·ªùi d√πng ---
    if user_factors:
        advice.append("\n--- üß© C√ÅC Y·∫æU T·ªê NGO·∫†I C·∫¢NH GHI NH·∫¨N ---")
        if user_factors.get("stress"):
            advice.append("‚ö†Ô∏è B·∫°n ƒëang c√≥ d·∫•u hi·ªáu cƒÉng th·∫≥ng. Stress l√†m tƒÉng th·ªùi gian Wake v√† gi·∫£m REM.")
        if user_factors.get("late_night"):
            advice.append("üåô Th·ª©c khuya l√†m r·ªëi lo·∫°n nh·ªãp sinh h·ªçc, gi·∫£m gi·∫•c ng·ªß s√¢u (N3).")
        if user_factors.get("device_usage"):
            advice.append("üì± S·ª≠ d·ª•ng thi·∫øt b·ªã ƒëi·ªán t·ª≠ tr∆∞·ªõc khi ng·ªß c√≥ th·ªÉ l√†m gi·∫£m ch·∫•t l∆∞·ª£ng N2 v√† REM.")
        if user_factors.get("caffeine"):
            advice.append("‚òï Caffeine c√≥ th·ªÉ k√©o d√†i th·ªùi gian Wake v√† gi·∫£m REM n·∫øu d√πng sau 16h.")
        if user_factors.get("alcohol"):
            advice.append("üç∑ R∆∞·ª£u, thu·ªëc l√° l√†m gi·∫£m N3 v√† REM, khi·∫øn gi·∫•c ng·ªß kh√¥ng ph·ª•c h·ªìi.")
        if not user_factors.get("exercise"):
            advice.append("üèÉ‚Äç‚ôÇÔ∏è Thi·∫øu v·∫≠n ƒë·ªông l√†m gi·∫£m th·ªùi l∆∞·ª£ng N3. H√£y t·∫≠p th·ªÉ d·ª•c nh·∫π bu·ªïi s√°ng ho·∫∑c chi·ªÅu.")


    # --- 3. X√°c ƒë·ªãnh nh√≥m tu·ªïi v√† L·ªçc Y·∫øu T·ªë ·∫¢nh H∆∞·ªüng ---
    age_int = int(age)
    age_group_key = None
    if 15 <= age_int <= 30:
        age_group_key = "thanh_thieu_nien_tre"
    elif 31 <= age_int <= 65:
        age_group_key = "trung_nien"
    elif age_int >= 66:
        age_group_key = "cao_tuoi"

    if not age_group_key:
        advice.append(f"Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c nh√≥m tu·ªïi cho {age_int}.")
        return advice

    # L·∫•y T·∫§T C·∫¢ c√°c y·∫øu t·ªë ti·ªÅm ·∫©n cho nh√≥m tu·ªïi n√†y
    all_potential_factors = sleep_impact_factors_detail[age_group_key]['factors']
    
    # --- 4. K·∫øt n·ªëi k·∫øt qu·∫£ ph√¢n t√≠ch (Poor Stages) v·ªõi Y·∫øu t·ªë (Factors) ---
    
    if poor_stages:
        advice.append(f"D·ª±a tr√™n nh√≥m tu·ªïi ({age_int}), ch√∫ng t√¥i ƒë√£ **k·∫øt h·ª£p** k·∫øt qu·∫£ ph√¢n t√≠ch gi·∫•c ng·ªß v·ªõi c√°c y·∫øu t·ªë b√™n ngo√†i c√≥ kh·∫£ nƒÉng g√¢y ra v·∫•n ƒë·ªÅ c·ªßa b·∫°n:")
        
        for p_stage in poor_stages:
            stage_name = p_stage['stage']
            stage_desc = p_stage['config']['desc']
            stage_percent = p_stage['percent'] * 100
            stage_emoji = p_stage['config']['emoji']

            # L·ªùi khuy√™n ƒë·∫ßu ti√™n: K·∫øt qu·∫£ ph√¢n t√≠ch
            advice.append(f"\n--- {stage_emoji} V·∫•n ƒë·ªÅ Ch√≠nh: {stage_desc} ({stage_percent:.1f}%) ---")

            # L·ªçc c√°c y·∫øu t·ªë t·ª´ nh√≥m tu·ªïi c√≥ t√°c ƒë·ªông ƒë·∫øn giai ƒëo·∫°n n√†y
            current_factors = [
                f['desc'] for f in all_potential_factors 
                if stage_name in f['impacts']
            ]
            
            if current_factors:
                advice.append(f"üí° CƒÉn c·ª© theo nh√≥m tu·ªïi, **{stage_desc} th·∫•p/cao** c√≥ th·ªÉ li√™n quan ƒë·∫øn c√°c y·∫øu t·ªë ti·ªÅm ·∫©n sau:")
                # L√†m cho l·ªùi khuy√™n c·ª• th·ªÉ h∆°n (v√≠ d·ª•: SC4822 c√≥ N3 th·∫•p)
                advice.extend([f"   - {f}" for f in current_factors])

            # (C·∫•p ƒë·ªô 3) K·∫øt n·ªëi tr·ª±c ti·∫øp v·ªõi user_factors
            if stage_name == 'Wake' and user_factors and user_factors.get('device_usage'):
                advice.append("üì± **K·∫øt n·ªëi tr·ª±c ti·∫øp**: T·ªâ l·ªá Wake cao v√† b·∫°n c√≥ d√πng ƒëi·ªán tho·∫°i tr∆∞·ªõc ng·ªß ‚Üí kh·∫£ nƒÉng cao √°nh s√°ng xanh ƒëang ·∫£nh h∆∞·ªüng tr·ª±c ti·∫øp ƒë·∫øn gi·∫•c ng·ªß c·ªßa b·∫°n.")
            if stage_name == 'N3' and user_factors and user_factors.get('late_night'):
                advice.append("üåô **K·∫øt n·ªëi tr·ª±c ti·∫øp**: T·ªâ l·ªá N3 th·∫•p v√† b·∫°n c√≥ th√≥i quen th·ª©c khuya ‚Üí n√™n c·ªë ƒë·ªãnh gi·ªù ng·ªß s·ªõm h∆°n ƒë·ªÉ c·∫£i thi·ªán gi·∫•c ng·ªß s√¢u.")



        # --- L·ªùi khuy√™n chung ƒë·ªÉ c·∫£i thi·ªán v√† gi·ªõi t√≠nh ---
        advice.append("\n--- ‚úÖ L·ªúI KHUY√äN H√ÄNH ƒê·ªòNG T·ªîNG QU√ÅT ---")
        
        # Th√™m l·ªùi khuy√™n v·ªÅ N3/REM (b·ªã th·∫•p)
        if any(p['stage'] == 'N3' for p in poor_stages):
            advice.append("üí§ ƒê·ªÉ tƒÉng c∆∞·ªùng **Gi·∫•c ng·ªß s√¢u (N3)**: T·∫≠p trung v√†o th√≥i quen ng·ªß ƒë·ªÅu ƒë·∫∑n, ƒë·∫£m b·∫£o ph√≤ng ng·ªß t·ªëi, m√°t, y√™n tƒ©nh, v√† tƒÉng c∆∞·ªùng t·∫≠p th·ªÉ d·ª•c v√†o ban ng√†y.")
        
        if any(p['stage'] == 'REM' for p in poor_stages):
            advice.append("üß† ƒê·ªÉ c·∫£i thi·ªán **t·ªâ l·ªá REM**: H·∫°n ch·∫ø tuy·ªát ƒë·ªëi c√°c ch·∫•t k√≠ch th√≠ch (r∆∞·ª£u, caffeine) 4-6 gi·ªù tr∆∞·ªõc khi ng·ªß v√† th·ª±c hi·ªán c√°c b√†i t·∫≠p th∆∞ gi√£n (thi·ªÅn, th·ªü s√¢u) ƒë·ªÉ gi·∫£m stress.")
            
        # Th√™m l·ªùi khuy√™n v·ªÅ Wake (b·ªã cao)
        if any(p['stage'] == 'Wake' for p in poor_stages):
            advice.append("‚ö°Ô∏è ƒê·ªÉ gi·∫£m **T·ªâ l·ªá th·ª©c gi·∫•c (Wake)**: ƒê√°nh gi√° l·∫°i vi·ªác s·ª≠ d·ª•ng thi·∫øt b·ªã ƒëi·ªán t·ª≠, √°nh s√°ng xanh 1 gi·ªù tr∆∞·ªõc ng·ªß. N·∫øu Wake cao v√† b·∫°n c√≥ d·∫•u hi·ªáu ng√°y, c·∫ßn c√¢n nh·∫Øc kh√°m b√°c sƒ© chuy√™n khoa h√¥ h·∫•p.")
            
        # L·ªùi khuy√™n theo gi·ªõi t√≠nh (t·ª´ logic c≈©)
        if gender.lower() == 'nam':
            advice.append("üí° **D√†nh cho Nam gi·ªõi**: C·∫ßn ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng N3 ƒë·ªÉ ph·ª•c h·ªìi th·ªÉ ch·∫•t t·ªët nh·∫•t.")
        elif gender.lower() == 'n·ªØ':
            advice.append("üí° **D√†nh cho N·ªØ gi·ªõi**: D·ªÖ b·ªã ·∫£nh h∆∞·ªüng b·ªüi stress v√† thay ƒë·ªïi hormone, c·∫ßn ∆∞u ti√™n c√°c k·ªπ thu·∫≠t gi·∫£m lo √¢u.")
    else:
        # Tr∆∞·ªùng h·ª£p ph√¢n t√≠ch ra k·∫øt qu·∫£ t·ªët
        advice.append("üéâ D·ªØ li·ªáu ph√¢n t√≠ch cho th·∫•y c√°c ch·ªâ s·ªë N3, REM v√† Wake c·ªßa b·∫°n ƒëang ·ªü m·ª©c l√Ω t∆∞·ªüng. H√£y ti·∫øp t·ª•c duy tr√¨ th√≥i quen sinh ho·∫°t hi·ªán t·∫°i!")
    
    return advice

# =========================================================
# üìä H√†m t·∫°o B·∫£ng T√≥m t·∫Øt Ch·∫•t l∆∞·ª£ng Gi·∫•c ng·ªß
# =========================================================
def generate_sleep_quality_table(stage_counts, sleep_start_time, age):
    """
    (C·∫¢I TI·∫æN) T·∫°o b·∫£ng t√≥m t·∫Øt ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß v·ªõi ƒë·ªãnh d·∫°ng ƒë·∫πp h∆°n
    v√† ƒë√°nh gi√° chi ti·∫øt h∆°n.
    """
    total_epochs = sum(stage_counts.values())
    if total_epochs == 0:
        return ["\n‚ö†Ô∏è Kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t·∫°o b·∫£ng ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß."]

    # --- 1. ƒê·ªãnh nghƒ©a ng∆∞·ª°ng v√† th√¥ng tin chi ti·∫øt cho t·ª´ng giai ƒëo·∫°n ---
    # Ng∆∞·ª°ng c√≥ th·ªÉ thay ƒë·ªïi m·ªôt ch√∫t theo ƒë·ªô tu·ªïi
    age_int = int(age) if age.isdigit() else 40 # M·∫∑c ƒë·ªãnh tu·ªïi trung ni√™n
    
    THRESHOLDS = {
        'Wake': {'range': (0.02, 0.08), 'desc': "Th·ª©c gi·∫•c", 'role': "Th·ªùi gian th·ª©c trong ƒë√™m."},
        'N1':   {'range': (0.02, 0.08), 'desc': "Ng·ªß n√¥ng", 'role': "Giai ƒëo·∫°n chuy·ªÉn ti·∫øp, d·ªÖ b·ªã ƒë√°nh th·ª©c."},
        'N2':   {'range': (0.45, 0.55), 'desc': "Ng·ªß v·ª´a", 'role': "Chi·∫øm ph·∫ßn l·ªõn th·ªùi gian ng·ªß, c·ªßng c·ªë tr√≠ nh·ªõ."},
        'N3':   {'range': (0.13, 0.23) if age_int > 60 else (0.15, 0.25), 'desc': "Ng·ªß s√¢u", 'role': "Ph·ª•c h·ªìi th·ªÉ ch·∫•t, tƒÉng tr∆∞·ªüng, th·∫£i ƒë·ªôc n√£o."},
        'REM':  {'range': (0.18, 0.23) if age_int > 60 else (0.20, 0.25), 'desc': "Ng·ªß m∆°", 'role': "X·ª≠ l√Ω c·∫£m x√∫c, s√°ng t·∫°o, c·ªßng c·ªë k·ªπ nƒÉng."}
    }

    # --- 2. X√¢y d·ª±ng d·ªØ li·ªáu cho b·∫£ng ---
    table_data = []
    STAGE_ORDER = ['Wake', 'N1', 'N2', 'N3', 'REM']

    for stage in STAGE_ORDER:
        count = stage_counts.get(stage, 0)
        percentage = count / total_epochs

        total_minutes = count * 0.5
        hours = int(total_minutes // 60)
        minutes = int(total_minutes % 60)
        duration_str = f"{hours}h {minutes}m"

        threshold_info = THRESHOLDS.get(stage)
        assessment_str = "N/A"
        recommendation_str = "N/A"

        if threshold_info:
            min_p, max_p = threshold_info['range']
            recommendation_str = f"{min_p*100:.0f}% - {max_p*100:.0f}%"
            
            # ƒê√°nh gi√° chi ti·∫øt h∆°n
            if percentage < min_p * 0.8: # R·∫•t th·∫•p
                assessment_str = "R·∫•t th·∫•p ‚ö†Ô∏è"
            elif percentage < min_p:
                assessment_str = "Th·∫•p (C·∫ßn c·∫£i thi·ªán)"
            elif percentage > max_p * 1.2: # R·∫•t cao
                assessment_str = "R·∫•t cao ‚ö†Ô∏è"
            elif percentage > max_p:
                assessment_str = "Cao (B·∫•t th∆∞·ªùng)"
            else:
                assessment_str = "T·ªët ‚úÖ"

        table_data.append({
            "Giai ƒëo·∫°n": f"{threshold_info['desc']} ({stage})",
            "M√¥ t·∫£": threshold_info['role'],
            "Th·ªùi l∆∞·ª£ng": duration_str,
            "T·ªâ l·ªá %": f"{percentage*100:.1f}%",
            "Ng∆∞·ª°ng Khuy·∫øn ngh·ªã": recommendation_str,
            "ƒê√°nh gi√°": assessment_str
        })

    # --- 3. T·∫°o chu·ªói b√°o c√°o t·ª´ d·ªØ li·ªáu b·∫£ng ---
    df = pd.DataFrame(table_data)
    report_lines = ["\n**üìä B·∫¢NG T√ìM T·∫ÆT CH·∫§T L∆Ø·ª¢NG GI·∫§C NG·ª¶**\n"]
    report_lines.append(df.to_markdown(index=False))

    # --- 4. Th√™m th√¥ng tin t·ªïng k·∫øt ---
    total_sleep_minutes = total_epochs * 0.5
    total_hours = int(total_sleep_minutes // 60)
    total_minutes_rem = int(total_sleep_minutes % 60)
    end_time = sleep_start_time + timedelta(minutes=total_sleep_minutes)

    summary_line = (
        f"\n*T·ªïng th·ªùi gian ghi nh·∫≠n: **{total_hours} gi·ªù {total_minutes_rem} ph√∫t** "
        f"(t·ª´ {sleep_start_time.strftime('%H:%M')} ƒë·∫øn {end_time.strftime('%H:%M')}).*"
    )
    report_lines.append(summary_line)

    return report_lines

# =========================================================
# üìä Ph√¢n t√≠ch nhi·ªÖu + tr·ª±c quan
# =========================================================
def generate_noise_impact_report(y_true, y_pred, config, subject_id="Unknown", output_dir="final_reports"):
    """
    S·ª¨A: Th√™m tham s·ªë output_dir ƒë·ªÉ l∆∞u b√°o c√°o v√†o ƒë√∫ng th∆∞ m·ª•c.
    """
    os.makedirs(output_dir, exist_ok=True)

    print("\n===== üìä PH√ÇN T√çCH ·∫¢NH H∆Ø·ªûNG NHI·ªÑU =====")
    is_clean_mask = (y_true != 5) # Nh√£n nhi·ªÖu l√† 5 trong file TrainLSTM6lop.py # type: ignore

    total_samples = len(y_true)
    noise_samples = np.sum(~is_clean_mask)
    print(f"T·ªïng m·∫´u: {total_samples}, Nhi·ªÖu: {noise_samples} ({noise_samples/total_samples*100:.2f}%)")

    # --- Ph√¢n t√≠ch hi·ªáu su·∫•t ---
    # 1. T·∫≠p CLEAN (kh√¥ng c√≥ nhi·ªÖu)
    y_true_clean = y_true[is_clean_mask]
    y_pred_clean = y_pred[is_clean_mask]
    f1_clean = f1_score(y_true_clean, y_pred_clean, average='macro', zero_division=0) # type: ignore
    kappa_clean = cohen_kappa_score(y_true_clean, y_pred_clean)

    # 2. T·∫≠p FULL (c√≥ nhi·ªÖu)
    f1_full = f1_score(y_true, y_pred, average='macro', zero_division=0) # type: ignore
    kappa_full = cohen_kappa_score(y_true, y_pred)

    print("\n--- So s√°nh hi·ªáu su·∫•t ---")
    print(f"‚úÖ Macro F1 (S·∫°ch): {f1_clean:.4f} | Kappa (S·∫°ch): {kappa_clean:.4f}")
    print(f"üî¥ Macro F1 (ƒê·∫ßy ƒë·ªß): {f1_full:.4f} | Kappa (ƒê·∫ßy ƒë·ªß): {kappa_full:.4f}")
    print(f"üìâ M·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng c·ªßa nhi·ªÖu (F1 gi·∫£m): {f1_clean - f1_full:.4f}")

    # --- Ph√¢n t√≠ch d·ª± ƒëo√°n tr√™n c√°c m·∫´u nhi·ªÖu ---
    if noise_samples > 0:
        y_pred_on_noise = y_pred[~is_clean_mask]
        noise_pred_counts = pd.Series(y_pred_on_noise).value_counts().sort_index()
        print("\nüìå Ph√¢n b·ªë d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh tr√™n c√°c m·∫´u th·ª±c s·ª± l√† nhi·ªÖu:")
        for stage, count in noise_pred_counts.items(): # type: ignore
            if stage < len(config.SLEEP_STAGE_LABELS):
                print(f"  - D·ª± ƒëo√°n l√† '{config.SLEEP_STAGE_LABELS[stage]}': {count} m·∫´u ({count / noise_samples * 100:.2f}%)")

    # --- Tr·ª±c quan h√≥a ---
    # Bi·ªÉu ƒë·ªì tr√≤n t·ªâ l·ªá nhi·ªÖu
    plt.figure(figsize=(6, 6))
    plt.pie([total_samples - noise_samples, noise_samples],
            labels=["S·∫°ch", "Nhi·ªÖu"],
            autopct="%1.1f%%", colors=["#66b3ff", "#ff6666"], startangle=90)
    plt.title(f"T·ªâ l·ªá S·∫°ch vs Nhi·ªÖu ({subject_id})")
    plt.savefig(os.path.join(output_dir, f"noise_ratio_{subject_id}.png"), dpi=300)
    plt.close()

    # Bi·ªÉu ƒë·ªì c·ªôt ph√¢n b·ªë d·ª± ƒëo√°n
    pred_labels = [config.SLEEP_STAGE_LABELS[i] for i in y_pred]
    plt.figure(figsize=(8, 6))
    sns.countplot(x=pred_labels, order=config.SLEEP_STAGE_LABELS, palette="viridis")
    plt.title(f"Ph√¢n b·ªë d·ª± ƒëo√°n ({subject_id})")
    plt.xlabel("Giai ƒëo·∫°n")
    plt.ylabel("S·ªë m·∫´u")
    plt.savefig(os.path.join(output_dir, f"pred_distribution_{subject_id}.png"), dpi=300)
    plt.close()


# =========================================================
# üìà V·∫Ω Timeline d·ª± ƒëo√°n gi·∫•c ng·ªß
# =========================================================
def plot_sleep_timeline(y_pred, sleep_start_time, config, subject_id="Unknown", output_dir="final_reports"):
    """
    S·ª¨A: Th√™m tham s·ªë output_dir ƒë·ªÉ l∆∞u b√°o c√°o v√†o ƒë√∫ng th∆∞ m·ª•c.
    """
    os.makedirs(output_dir, exist_ok=True)

    epochs = np.arange(len(y_pred))
    times = [sleep_start_time + timedelta(seconds=30 * int(i)) for i in epochs]

    plt.figure(figsize=(14, 5))
    # S·ª≠ d·ª•ng plt.step ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì b·∫≠c thang, tr·ª±c quan h∆°n
    plt.step(times, y_pred, where='post', color='royalblue', linewidth=2)
    # S·ª¨A L·ªñI: Cung c·∫•p ƒë·ªß nh√£n cho t·∫•t c·∫£ c√°c v·ªã tr√≠.
    # config.SLEEP_STAGE_LABELS gi·ªù ƒë√¢y c√≥ 6 ph·∫ßn t·ª≠ t·ª´ TrainLSTM6lop.py # type: ignore
    # range(len(config.SLEEP_STAGE_LABELS)) s·∫Ω l√† range(6) -> [0, 1, 2, 3, 4, 5]
    plt.yticks(range(len(config.SLEEP_STAGE_LABELS)), config.SLEEP_STAGE_LABELS)
    plt.gca().invert_yaxis() # ƒê∆∞a Wake l√™n tr√™n c√πng
    plt.xlabel("Th·ªùi gian")
    plt.ylabel("Giai ƒëo·∫°n")
    plt.title(f"Timeline gi·∫•c ng·ªß ({subject_id})")
    plt.grid(True, axis="y", linestyle="--", alpha=0.7)
    plt.tight_layout()
    plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%H:%M'))
    timeline_path = os.path.join(output_dir, f"sleep_timeline_{subject_id}.png")
    plt.savefig(timeline_path, dpi=300)
    plt.close()

    print(f"‚úÖ Timeline gi·∫•c ng·ªß ƒë√£ l∆∞u: {timeline_path}")


# =========================================================
# üîç Grid Search cho c·∫•u h√¨nh inference t·ªët nh·∫•t
# =========================================================
def run_inference_grid_search(model, X_proc, y_true):
    """
    Ch·∫°y grid search tr√™n c√°c tham s·ªë inference ƒë·ªÉ t√¨m F1-score macro t·ªët nh·∫•t.
    T∆∞∆°ng t·ª± logic trong debug_infer.py.
    """
    best = {"f1": -1}
    temps = [0.8, 1.0, 1.2, 1.5, 1.8] # <-- D√£y Temp M·ªöI
    trans_diags = [0.8, 0.5, 0.3, 0.1] # <-- D√£y Diag M·ªöI
    channel_options = [False, True] # False: normal, True: swap
    hmm_options = [True, False] # True: HMM, False: argmax

    print("\n===== üîç B·∫Øt ƒë·∫ßu Grid Search c·∫•u h√¨nh Inference =====")

    for swap in channel_options:
        X_try = X_proc[..., ::-1] if swap else X_proc
        try:
            probs = model.predict(X_try, verbose=0)
        except Exception as e:
            print(f"L·ªói khi d·ª± ƒëo√°n v·ªõi swap={swap}: {e}")
            continue

        for temp in temps:
            p_tmp = np.clip(probs, 1e-12, 1.0)**(1.0/float(temp))
            p_tmp = p_tmp / p_tmp.sum(axis=1, keepdims=True)

            for apply_hmm in hmm_options:
                if not apply_hmm:
                    # Tr∆∞·ªùng h·ª£p kh√¥ng d√πng HMM, ch·ªâ argmax
                    preds = np.argmax(p_tmp, axis=1)
                    td = None # Kh√¥ng c√≥ HMM diag
                    f1 = f1_score(y_true, preds, average='macro', zero_division=0)
                    if f1 > best["f1"]:
                        best.update({"f1": f1, "swap": swap, "temp": temp,
                                     "apply_hmm": apply_hmm, "trans_diag": td, "preds": preds})
                    continue

                # Tr∆∞·ªùng h·ª£p d√πng HMM v·ªõi c√°c diag kh√°c nhau
                for td in trans_diags:
                    # clean_eval=True n·∫øu kh√¥ng c√≥ nh√£n Noise trong y_true
                    clean_eval = not np.any(y_true == 5)
                    preds = hmm_smoothing_viterbi(p_tmp, trans_diag=td, clean_eval=clean_eval)
                    f1 = f1_score(y_true, preds, average='macro', zero_division=0)
                    if f1 > best["f1"]:
                        best.update({"f1": f1, "swap": swap, "temp": temp,
                                     "apply_hmm": apply_hmm, "trans_diag": td, "preds": preds})

    print("\n--- K·∫øt qu·∫£ Grid Search ---")
    if best['f1'] > -1:
        best_config_str = (
            f"F1: {best['f1']:.4f} | Swap: {best['swap']} | Temp: {best['temp']} | "
            f"HMM: {best['apply_hmm']} | Diag: {best['trans_diag']}"
        )
        print(f"‚úÖ C·∫•u h√¨nh t·ªët nh·∫•t: {best_config_str}")
        # Tr·∫£ v·ªÅ d·ª± ƒëo√°n t·ªët nh·∫•t
        return best["preds"]
    else:
        print("‚ö†Ô∏è Grid search kh√¥ng t√¨m th·∫•y c·∫•u h√¨nh h·ª£p l·ªá.")
        # Fallback v·ªÅ argmax c·ªßa probs g·ªëc
        return np.argmax(model.predict(X_proc, verbose=0), axis=1)

    # th√™m v√†o cu·ªëi analyze_sleep_CNN.py

def analyze_edf(
    edf_path,
    model=None,
    model_path=None,
    bed_time_str="22:00",
    wake_time_str="06:30",
    age="30",
    gender="nam",
    mode="1",
    output_dir="analysis_outputs",
    apply_gridsearch=False
):
    """
    Ph√¢n t√≠ch file EDF v√† tr·∫£ v·ªÅ dict:
    {
      "alarms": [{"time":"05:52 PM", "description":"..."} , ...],
      "stage_counts": {...},
      "sleep_score": int,
      "sleep_rating": str,
      "reports": [...strings...],
      "timeline_path": "/full/path/to/png"
    }

    N·∫øu model kh√¥ng ƒë∆∞·ª£c truy·ªÅn v√†o, h√†m s·∫Ω c·ªë load model t·ª´ model_path.
    """
    os.makedirs(output_dir, exist_ok=True)

    # 1) load model n·∫øu c·∫ßn
    if model is None:
        if model_path:
            try:
                model = load_trained_model_for_inference(model_path)
            except Exception as e:
                # try fallback to tf.keras load (may fail for custom layers)
                import tensorflow as tf
                model = tf.keras.models.load_model(model_path, compile=False)
        else:
            raise ValueError("No model provided and no model_path given.")

    # 2) ƒë·ªçc EDF v√† t·∫°o epochs 30s
    import mne, numpy as np, scipy.signal
    raw = mne.io.read_raw_edf(str(edf_path), preload=True, verbose=False)

    # c·ªë ch·ªçn 2 channel gi·ªëng training, n·∫øu kh√¥ng c√≥ -> l·∫•y 2 ƒë·∫ßu ti√™n
    preferred = ["EEG Fpz-Cz", "EEG Pz-Oz"]
    avail = [c for c in preferred if c in raw.ch_names]
    if not avail:
        # fallback: th·ª≠ t√™n short or first two channels
        if len(raw.ch_names) >= 2:
            avail = raw.ch_names[:2]
        else:
            avail = raw.ch_names[:]  # whatever available
    raw.pick_channels(avail)

    # VF: ƒë·∫£m b·∫£o sampling rate l√† s·ªë nguy√™n
    sfreq = int(round(raw.info.get("sfreq", 100)))
    # t·∫°o epoch 30s (mne.make_fixed_length_epochs)
    epochs = mne.make_fixed_length_epochs(raw, duration=30.0, overlap=0.0, preload=True, verbose=False)
    X = epochs.get_data()  # shape (n_epochs, n_channels, n_times)
    if X is None or len(X) == 0:
        raise RuntimeError("No epochs extracted from EDF - check file and channels.")

    # chu·∫©n ho√° gi·ªëng training: resample m·ªói epoch t·ªõi CONFIG.TARGET_LENGTH_CNN
    X_list = []
    for i in range(X.shape[0]):
        xi = X[i].astype(np.float32)  # (channels, times)
        # transpose -> (times, channels) to resample along time axis
        xi_t = xi.T
        xi_r = scipy.signal.resample(xi_t, CONFIG.TARGET_LENGTH_CNN, axis=0).astype(np.float32)
        mean = xi_r.mean(axis=0, keepdims=True)
        std = xi_r.std(axis=0, keepdims=True) + 1e-8
        xi_norm = (xi_r - mean) / std
        X_list.append(xi_norm)
    X_proc = np.stack(X_list).astype(np.float32)  # (n_epochs, time_points, channels)

    # 3) predict probabilities
    X_input = X_proc

    # ‚ö†Ô∏è N·∫øu model y√™u c·∫ßu input (None,100), c√≤n X_proc ƒëang l√† (N,1500,2)
    if len(model.input_shape) >= 2:
        expected_shape = model.input_shape[1]
        if isinstance(expected_shape, int) and expected_shape == 100 and X_input.ndim == 3:
            print(f"[WARN] Reshaping X from {X_input.shape} ‚Üí (N, 100)")
            # Flatten theo th·ªùi gian v√† k√™nh r·ªìi resample v·ªÅ 100 ƒëi·ªÉm
            import scipy.signal
            N = X_input.shape[0]
            X_flat = X_input.reshape(N, -1)  # (N, 1500*2)
            X_resamp = scipy.signal.resample(X_flat, 100, axis=1)
            X_input = X_resamp.astype(np.float32)

    probs = model.predict(X_input, verbose=0)


    # optionally apply temperature / gridsearch - keep it simple here
    # 4) HMM smoothing (n·∫øu c√≥)
    try:
        preds = hmm_smoothing_viterbi(probs, trans_diag=CONFIG.HMM_SMOOTHING_DIAG, clean_eval=False)
    except Exception:
        preds = np.argmax(probs, axis=1)

    # 5) map to stage labels (strings)
    try:
        y_pred_stages = [CONFIG.SLEEP_STAGE_LABELS[int(p)] for p in preds]
    except Exception:
        y_pred_stages = []

    # 6) stage counts
    from collections import Counter
    stage_counts = Counter(y_pred_stages)

    # 7) calculate sleep quality score
    sleep_score, sleep_rating = calculate_sleep_quality_score(stage_counts, age)

    # 8) compute optimal wakeup times (bed_time_str -> datetime)
    # make bed_time base date today
    try:
        bed_dt = datetime.combine(date.today(), datetime.strptime(bed_time_str, "%H:%M").time())
    except Exception:
        bed_dt = datetime.combine(date.today(), dt_time(hour=22, minute=0))
    optimal_times = get_optimal_wakeup_times(y_pred_stages, bed_dt, mode, age, gender)

    # format alarms (use 12h with AM/PM)
    alarms = []
    for tstr in optimal_times:
        # tstr is produced as "%H:%M" in get_optimal_wakeup_times, convert to 12h
        try:
            tdt = datetime.strptime(tstr, "%H:%M")
            formatted = tdt.strftime("%I:%M %p").lstrip("0")
        except Exception:
            formatted = tstr
        alarms.append({"time": formatted, "description": "From model"})

    # 9) build reports
    sleep_quality_report = generate_sleep_quality_table(stage_counts, bed_dt, age)
    stage_impact_report = generate_stage_impact_report(stage_counts, age, SLEEP_STAGE_IMPACT_SUMMARY)

    # 10) save timeline figure (calls your plot function)
    try:
        timeline_fn = os.path.join(output_dir, f"sleep_timeline_{Path(edf_path).stem}.png")
        # plot_sleep_timeline saves file and prints path; we can call with output_dir
        plot_sleep_timeline(preds, bed_dt, CONFIG, subject_id=Path(edf_path).stem, output_dir=output_dir)
    except Exception as e:
        timeline_fn = None

    result = {
        "alarms": alarms,
        "stage_counts": dict(stage_counts),
        "sleep_score": int(sleep_score),
        "sleep_rating": sleep_rating,
        "sleep_quality_table": sleep_quality_report,
        "stage_impact_report": stage_impact_report,
        "timeline_path": timeline_fn
    }
    return result


# =========================================================
#  MAIN
# =========================================================
if __name__ == "__main__":
    print("\n\n===== üí° Ph√¢n t√≠ch d·ªØ li·ªáu v√† ƒë·ªÅ xu·∫•t gi·ªù th·ª©c d·∫≠y =====")
    
    subject_to_analyze = input("‚ñ∂Ô∏è Nh·∫≠p t√™n file d·ªØ li·ªáu s√≥ng (v√≠ d·ª•: 'SC4581'): ")
    age = input("‚ñ∂Ô∏è Nh·∫≠p tu·ªïi: ")
    gender = input("‚ñ∂Ô∏è Nh·∫≠p gi·ªõi t√≠nh (Nam/N·ªØ): ")

    while True:
        sleep_start_time_str = input("‚ñ∂Ô∏è Nh·∫≠p gi·ªù ƒëi ng·ªß (HH:MM, v√≠ d·ª•: 22:00): ")
        try:
            sleep_start_time = datetime.strptime(sleep_start_time_str, "%H:%M")
            break
        except ValueError:
            print("‚ùå Sai ƒë·ªãnh d·∫°ng, th·ª≠ l·∫°i.")

    # C·∫•p ƒë·ªô 1: M·ªü r·ªông d·ªØ li·ªáu ƒë·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng
    print("\nüåô M·ªôt v√†i c√¢u h·ªèi nhanh ƒë·ªÉ c√° nh√¢n h√≥a ph√¢n t√≠ch:")
    stress = input("‚ñ∂Ô∏è B·∫°n c√≥ ƒëang cƒÉng th·∫≥ng, lo √¢u ho·∫∑c stress kh√¥ng? (y/n): ").lower()
    late_night = input("‚ñ∂Ô∏è B·∫°n c√≥ th∆∞·ªùng xuy√™n th·ª©c khuya (sau 23h) kh√¥ng? (y/n): ").lower()
    device_usage = input("‚ñ∂Ô∏è B·∫°n c√≥ d√πng ƒëi·ªán tho·∫°i/m√°y t√≠nh tr∆∞·ªõc khi ng·ªß? (y/n): ").lower()
    caffeine = input("‚ñ∂Ô∏è B·∫°n c√≥ d√πng c√† ph√™, tr√† ho·∫∑c ch·∫•t k√≠ch th√≠ch bu·ªïi chi·ªÅu/t·ªëi kh√¥ng? (y/n): ").lower()
    alcohol = input("‚ñ∂Ô∏è B·∫°n c√≥ s·ª≠ d·ª•ng r∆∞·ª£u ho·∫∑c thu·ªëc l√° kh√¥ng? (y/n): ").lower()
    exercise = input("‚ñ∂Ô∏è B·∫°n c√≥ t·∫≠p th·ªÉ d·ª•c √≠t nh·∫•t 3 l·∫ßn/tu·∫ßn kh√¥ng? (y/n): ").lower()

    user_factors = {
        "stress": stress == "y",
        "late_night": late_night == "y",
        "device_usage": device_usage == "y",
        "caffeine": caffeine == "y",
        "alcohol": alcohol == "y",
        "exercise": exercise == "y"
    }

    # --- S·ª¨A: Kh√¥i ph·ª•c logic ch·ªçn model g·ªëc, ∆∞u ti√™n model ƒë√£ fine-tune ---
    best_model_path = None
    base_model_path = open("best_model_path.txt").read().strip()
    base_model_dir = os.path.dirname(base_model_path)
    # ƒê∆∞·ªùng d·∫´n t·ªõi model fine-tune v2 ti·ªÅm nƒÉng
    subject_specific_model_path = os.path.join(base_model_dir, f"fine_tuned_v2_{subject_to_analyze}.keras")

    # 1. ∆Øu ti√™n t√¨m model ƒë√£ fine-tune ri√™ng cho subject
    if os.path.exists(subject_specific_model_path):
        best_model_path = subject_specific_model_path
        print(f"‚úÖ T√¨m th·∫•y model ƒë√£ fine-tune ri√™ng cho subject: {best_model_path}")
    else:
        # 2. N·∫øu kh√¥ng c√≥, h·ªèi ng∆∞·ªùi d√πng c√≥ mu·ªën fine-tune kh√¥ng
        print(f"‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y model ri√™ng cho '{subject_to_analyze}'.")
        do_finetune = input("‚ñ∂Ô∏è B·∫°n c√≥ mu·ªën fine-tune m·ªôt model m·ªõi cho subject n√†y ƒë·ªÉ c√≥ k·∫øt qu·∫£ t·ªët nh·∫•t? (y/n): ").lower()
        if do_finetune == 'y':
            print(f"\n===== üöÄ B·∫Øt ƒë·∫ßu Fine-tuning cho {subject_to_analyze} t·ª´ model '{base_model_path}' =====")
            best_model_path = run_finetuning_for_subject_cnn(subject_to_analyze, base_model_path)
            print(f"===== ‚úÖ Fine-tuning ho√†n t·∫•t. Model m·ªõi: '{best_model_path}' =====\n")

    # 3. N·∫øu v·∫´n kh√¥ng c√≥ model (ng∆∞·ªùi d√πng t·ª´ ch·ªëi fine-tune), fallback v·ªÅ model chung
    if not best_model_path:
        print(f"‚ö†Ô∏è  C·∫¢NH B√ÅO: S·ª≠ d·ª•ng model chung '{base_model_path}' v√¨ kh√¥ng c√≥ model ri√™ng ho·∫∑c ng∆∞·ªùi d√πng t·ª´ ch·ªëi fine-tune. K·∫øt qu·∫£ c√≥ th·ªÉ kh√¥ng t·ªëi ∆∞u.")
        best_model_path = base_model_path

    if not best_model_path:
        print("‚ùå Kh√¥ng th·ªÉ x√°c ƒë·ªãnh model ƒë·ªÉ s·ª≠ d·ª•ng. Vui l√≤ng ch·∫°y training ho·∫∑c fine-tuning tr∆∞·ªõc.")
        exit()

    print(f"‚úÖ S·ª≠ d·ª•ng model: {best_model_path}")
    model = load_trained_model_for_inference(best_model_path)

    # Load v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu cho subject
    X_raw, y_subject_true = load_single_subject(subject_to_analyze)
    if X_raw is None:
        print(f"‚ùå Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu cho subject {subject_to_analyze}.")
        exit()

    # Ti·ªÅn x·ª≠ l√Ω gi·ªëng h·ªát trong training
    X_list = []
    for i in range(X_raw.shape[0]):
        x = X_raw[i].astype(np.float32)
        x_r = scipy.signal.resample(x, CONFIG.TARGET_LENGTH_CNN, axis=0).astype(np.float32)
        mean = x_r.mean(axis=0, keepdims=True)
        std = x_r.std(axis=0, keepdims=True) + 1e-8
        X_list.append((x_r - mean) / std)
    X_subject = np.stack(X_list).astype(np.float32)
    y_subject_true = np.array(y_subject_true)

    # Ch·∫°y grid search ƒë·ªÉ t√¨m d·ª± ƒëo√°n t·ªët nh·∫•t
    y_pred_final = run_inference_grid_search(model, X_subject, y_subject_true)

    if y_pred_final is not None and len(y_pred_final) > 0:
        # S·ª¨A: X√°c ƒë·ªãnh th∆∞ m·ª•c output d·ª±a tr√™n ƒë∆∞·ªùng d·∫´n model
        # V√≠ d·ª•: n·∫øu model_path l√† 'results_cnn_6lop_.../checkpoints/model.keras'
        # th√¨ output_dir s·∫Ω l√† 'results_cnn_6lop_.../final_reports'
        output_dir = os.path.join(os.path.dirname(os.path.dirname(best_model_path)), "final_reports")

        # --- DEBUG: save per-channel stats + PSD for comparison ---
        try:
            os.makedirs("debug_plots_CNN", exist_ok=True)
            # X_subject shape = (n_epochs, time_points, channels)
            X = np.array(X_subject)  # ensure ndarray
            n_epochs, n_t, n_ch = X.shape
            ch_means = X.reshape(-1, n_ch).mean(axis=0)
            ch_stds = X.reshape(-1, n_ch).std(axis=0)
            np.save("debug_plots/subject_per_channel_mean.npy", ch_means)
            np.save("debug_plots/subject_per_channel_std.npy", ch_stds)
            print("DEBUG: per-channel mean/std saved:", ch_means, ch_stds)

            # PSD for epoch 0 each channel
            from scipy.signal import welch
            sf = 100  # typical sfreq ‚Äî thay n·∫øu kh√°c (m·ªôt s·ªë file in ra sfreq=100)
            fig, axs = plt.subplots(n_ch, 1, figsize=(8, 2.5 * n_ch))
            for c in range(min(n_ch, 2)): # Gi·ªõi h·∫°n v·∫Ω 2 k√™nh ƒë·ªÉ tr√°nh l·ªói n·∫øu c√≥ nhi·ªÅu k√™nh
                f, Pxx = welch(X[0, :, c], fs=sf, nperseg=512)
                axs[c].semilogy(f, Pxx)
                axs[c].set_xlabel("Hz"); axs[c].set_ylabel("PSD")
                axs[c].set_title(f"Subject {subject_to_analyze} PSD epoch 0 ch{c}")
            plt.tight_layout()
            plt.savefig(f"debug_plots/{subject_to_analyze}_epoch0_psd.png", dpi=150)
            plt.close()
            print(f"DEBUG: saved PSD -> debug_plots/{subject_to_analyze}_epoch0_psd.png")

            # If you have a saved training example to compare (optional)
            train_sample_path = "debug_plots/training_epoch_sample.npy"
            if os.path.exists(train_sample_path):
                train_epoch = np.load(train_sample_path)  # expects shape (time, channels)
                fig, axs = plt.subplots(n_ch, 1, figsize=(8, 2.5 * n_ch))
                for c in range(min(n_ch, 2)):
                    f_s, P_s = welch(train_epoch[:, c], fs=sf, nperseg=512)
                    f_x, P_x = welch(X[0, :, c], fs=sf, nperseg=512)
                    axs[c].semilogy(f_s, P_s, label="train", alpha=0.8)
                    axs[c].semilogy(f_x, P_x, label="subject", alpha=0.8)
                    axs[c].legend()
                    axs[c].set_title(f"PSD ch{c} train vs subject")
                plt.tight_layout()
                plt.savefig(f"debug_plots/{subject_to_analyze}_psd_vs_train.png", dpi=150)
                plt.close()
                print("DEBUG: saved PSD comparison with training sample")

        except Exception as _e:
            print("DEBUG: failed saving channel stats/PSD:", _e)

        # Ph√¢n t√≠ch nhi·ªÖu
        generate_noise_impact_report(y_subject_true, y_pred_final, CONFIG, subject_id=subject_to_analyze, output_dir=output_dir)

        # V·∫Ω timeline
        plot_sleep_timeline(y_pred_final, sleep_start_time, CONFIG, subject_id=subject_to_analyze, output_dir=output_dir)

        # --- FIX: t·∫°o danh s√°ch t√™n stage t·ª´ nh√£n s·ªë ƒë·ªÉ d√πng cho g·ª£i √Ω gi·ªù th·ª©c d·∫≠y ---
        try:
            y_pred_stages = [CONFIG.SLEEP_STAGE_LABELS[int(x)] for x in np.array(y_pred_final).astype(int)]
        except Exception:
            y_pred_stages = []

        # T√≠nh to√°n t·∫ßn su·∫•t c√°c giai ƒëo·∫°n d·ª± ƒëo√°n
        stage_counts = Counter(y_pred_stages)
        print("\nüìä Ph√¢n b·ªë Giai ƒëo·∫°n Gi·∫•c ng·ªß (S·ªë Epoch):", stage_counts)

        # --- T√≠nh v√† hi·ªÉn th·ªã ƒëi·ªÉm ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß ---
        sleep_score, sleep_rating = calculate_sleep_quality_score(stage_counts, age)
        print("\n" + "‚ïê"*25 + " ƒê√ÅNH GI√Å T·ªîNG QUAN " + "‚ïê"*25)
        print(f"üíØ ƒêi·ªÉm ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß c·ªßa b·∫°n: {sleep_score} / 100")
        print(f"‚≠ê X·∫øp h·∫°ng: {sleep_rating}")
        print("‚ïê"*70)

        # --- T·∫°o B√°o c√°o To√†n di·ªán: Ph√¢n t√≠ch nguy√™n nh√¢n v√† L·ªùi khuy√™n ---
        print("\n" + "‚ïê"*20 + " B√ÅO C√ÅO PH√ÇN T√çCH GI·∫§C NG·ª¶ CHI TI·∫æT " + "‚ïê"*20)

        # In b·∫£ng t√≥m t·∫Øt ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß
        sleep_quality_report = generate_sleep_quality_table(stage_counts, sleep_start_time, age)
        for line in sleep_quality_report:
            print(line)

        # In b·∫£ng ·∫£nh h∆∞·ªüng c√° nh√¢n h√≥a
        stage_impact_report = generate_stage_impact_report(stage_counts, age, SLEEP_STAGE_IMPACT_SUMMARY)
        for line in stage_impact_report:
            print(line)

        # --- ƒê·ªÅ xu·∫•t gi·ªù th·ª©c d·∫≠y ---
        print("\n" + "‚ïê"*25 + " ƒê·ªÄ XU·∫§T GI·ªú TH·ª®C D·∫¨Y " + "‚ïê"*25)
        print("B·∫°n mu·ªën th·ª©c d·∫≠y theo ti√™u ch√≠ n√†o?")
        print("1. D·∫≠y trong giai ƒëo·∫°n nh·∫π (N1, N2, REM)")
        print("2. D·∫≠y sau m·ªói chu k·ª≥ 90 ph√∫t")
        choice = input("‚ñ∂Ô∏è Nh·∫≠p l·ª±a ch·ªçn (1 ho·∫∑c 2): ")
 
        print(f"\nüìå Ng·ªß l√∫c: {sleep_start_time_str}")
        print(f"üë§ Tu·ªïi: {age}, Gi·ªõi t√≠nh: {gender}")
 
        optimal_times = get_optimal_wakeup_times(y_pred_stages, sleep_start_time, choice, age, gender)
        if optimal_times:
            print("\n‚è∞ Gi·ªù th·ª©c d·∫≠y t·ªëi ∆∞u (ch·ªçn ch·∫ø ƒë·ªô " + choice + "):")
            for i, t in enumerate(optimal_times, 1):
                print(f"   {i}. {t}")
        else:
            print("‚ö†Ô∏è Kh√¥ng c√≥ gi·ªù th·ª©c d·∫≠y t·ªëi ∆∞u.")

        # --- L·ªùi khuy√™n c√° nh√¢n h√≥a ---
        # G·ªçi h√†m ƒë·ªÉ l·∫•y l·ªùi khuy√™n c√° nh√¢n h√≥a
        final_advice = get_personalized_advice(age, gender, stage_counts, SLEEP_IMPACT_FACTORS_DETAIL, user_factors)
 
        print("\n" + "‚ïê"*20 + " L·ªúI KHUY√äN C√Å NH√ÇN H√ìA & NGUY√äN NH√ÇN " + "‚ïê"*20)
        for i, line in enumerate(final_advice):
            print(line)
        print("‚ïê"*70)
    else:
        print(f"‚ùå Kh√¥ng th·ªÉ x·ª≠ l√Ω cho subject {subject_to_analyze}.")
